{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ‚è±Ô∏è Temporal Steering with GPT-2 - Interactive Demo\n",
    "\n",
    "**Control GPT-2's temporal scope in real-time** using pre-trained steering vectors!\n",
    "\n",
    "Move the slider to shift between:\n",
    "- üî• **Immediate/Tactical** thinking (-1.0)\n",
    "- üå± **Long-term/Strategic** thinking (+1.0)\n",
    "\n",
    "This demo uses **Contrastive Activation Addition (CAA)** - a technique that extracts \"steering vectors\" representing the difference between immediate and long-term thinking.\n",
    "\n",
    "---\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-temporal--steering-blue)](https://github.com/justinshenk/temporal-steering)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers torch ipywidgets\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load Model & Pre-trained Steering Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2\n",
    "print(\"Loading GPT-2...\")\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.eval()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"‚úì Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pre-trained steering vectors\n",
    "import urllib.request\n",
    "\n",
    "print(\"Downloading pre-trained steering vectors...\")\n",
    "url = \"https://raw.githubusercontent.com/justinshenk/temporal-steering/main/steering_vectors/temporal_steering.json\"\n",
    "\n",
    "try:\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        data = json.loads(response.read())\n",
    "    \n",
    "    steering_vectors = {\n",
    "        int(layer): np.array(vec)\n",
    "        for layer, vec in data['layer_vectors'].items()\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úì Loaded vectors for {len(steering_vectors)} layers\")\n",
    "    print(f\"  Vector dimension: {len(steering_vectors[0])}\")\n",
    "    print(f\"  Metadata: {data['metadata']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not download from GitHub: {e}\")\n",
    "    print(\"Using fallback: Extracting steering vectors locally...\")\n",
    "    print(\"(This will take a few minutes)\")\n",
    "    \n",
    "    # Fallback: Quick extraction from a few prompt pairs\n",
    "    def extract_quick_vectors(model, tokenizer, device):\n",
    "        pairs = [\n",
    "            {\"imm\": \"Develop a 1 week plan to improve team productivity.\", \n",
    "             \"long\": \"Develop a 20 year plan to improve team productivity.\"},\n",
    "            {\"imm\": \"Develop a 1 month plan to address climate change.\",\n",
    "             \"long\": \"Develop a 50 year plan to address climate change.\"},\n",
    "            {\"imm\": \"Develop a 1 week plan to expand operations.\",\n",
    "             \"long\": \"Develop a 15 year plan to expand operations.\"},\n",
    "        ]\n",
    "        \n",
    "        n_layers = len(model.transformer.h)\n",
    "        layer_contrasts = {layer: [] for layer in range(n_layers)}\n",
    "        \n",
    "        for pair in pairs:\n",
    "            for prompt_type in ['imm', 'long']:\n",
    "                activations = {}\n",
    "                \n",
    "                def hook_fn(layer_num):\n",
    "                    def hook(module, input, output):\n",
    "                        activations[layer_num] = output[0].detach()\n",
    "                    return hook\n",
    "                \n",
    "                hooks = []\n",
    "                for i, layer in enumerate(model.transformer.h):\n",
    "                    hooks.append(layer.register_forward_hook(hook_fn(i)))\n",
    "                \n",
    "                inputs = tokenizer(pair[prompt_type], return_tensors='pt').to(device)\n",
    "                with torch.no_grad():\n",
    "                    model(**inputs)\n",
    "                \n",
    "                for hook in hooks:\n",
    "                    hook.remove()\n",
    "                \n",
    "                pair[f'{prompt_type}_acts'] = activations\n",
    "            \n",
    "            for layer in range(n_layers):\n",
    "                imm_vec = pair['imm_acts'][layer][0, -1, :].cpu().numpy()\n",
    "                long_vec = pair['long_acts'][layer][0, -1, :].cpu().numpy()\n",
    "                layer_contrasts[layer].append(long_vec - imm_vec)\n",
    "        \n",
    "        return {layer: np.stack(contrasts).mean(axis=0) \n",
    "                for layer, contrasts in layer_contrasts.items()}\n",
    "    \n",
    "    steering_vectors = extract_quick_vectors(model, tokenizer, device)\n",
    "    print(f\"‚úì Extracted vectors for {len(steering_vectors)} layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Steering System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalSteering:\n",
    "    def __init__(self, model, tokenizer, steering_vectors, target_layers=None):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.steering_vectors = steering_vectors\n",
    "        \n",
    "        if target_layers is None:\n",
    "            n_layers = len(model.transformer.h)\n",
    "            start = max(0, n_layers - 8)\n",
    "            self.target_layers = list(range(start, n_layers))\n",
    "        else:\n",
    "            self.target_layers = target_layers\n",
    "    \n",
    "    def generate(self, prompt, steering_strength=0.0, max_length=100, temperature=0.7):\n",
    "        inputs = self.tokenizer(prompt, return_tensors='pt').to(self.model.device)\n",
    "        hooks = []\n",
    "        \n",
    "        def make_hook(layer_idx, strength):\n",
    "            def hook(module, input, output):\n",
    "                hidden_states = output[0]\n",
    "                if layer_idx in self.steering_vectors:\n",
    "                    steering_vec = torch.tensor(\n",
    "                        self.steering_vectors[layer_idx],\n",
    "                        dtype=hidden_states.dtype,\n",
    "                        device=hidden_states.device\n",
    "                    )\n",
    "                    hidden_states = hidden_states + strength * steering_vec\n",
    "                return (hidden_states,) + output[1:]\n",
    "            return hook\n",
    "        \n",
    "        for layer_idx in self.target_layers:\n",
    "            hooks.append(self.model.transformer.h[layer_idx].register_forward_hook(\n",
    "                make_hook(layer_idx, steering_strength)\n",
    "            ))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output_ids = self.model.generate(\n",
    "                inputs['input_ids'],\n",
    "                max_length=max_length,\n",
    "                temperature=temperature,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        return self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "steering = TemporalSteering(model, tokenizer, steering_vectors)\n",
    "print(f\"‚úì Steering system ready (layers {steering.target_layers[0]}-{steering.target_layers[-1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Interactive Demo\n",
    "\n",
    "**Adjust the slider and click Generate** to see how temporal steering affects GPT-2's responses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets\n",
    "prompt_input = widgets.Textarea(\n",
    "    value='What should policymakers prioritize to address climate change?',\n",
    "    placeholder='Enter your prompt...',\n",
    "    description='Prompt:',\n",
    "    layout=widgets.Layout(width='100%', height='100px')\n",
    ")\n",
    "\n",
    "steering_slider = widgets.FloatSlider(\n",
    "    value=0.0,\n",
    "    min=-1.0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description='Temporal Steering:',\n",
    "    continuous_update=False,\n",
    "    readout_format='.1f',\n",
    "    layout=widgets.Layout(width='95%')\n",
    ")\n",
    "\n",
    "steering_label = widgets.HTML(\n",
    "    value='<div style=\"text-align: center; font-size: 16px; font-weight: bold; color: #667eea; padding: 10px;\">‚öñÔ∏è Neutral (0.0)</div>'\n",
    ")\n",
    "\n",
    "temp_slider = widgets.FloatSlider(\n",
    "    value=0.7,\n",
    "    min=0.3,\n",
    "    max=1.2,\n",
    "    step=0.1,\n",
    "    description='Temperature:',\n",
    "    continuous_update=False,\n",
    "    readout_format='.1f',\n",
    "    layout=widgets.Layout(width='45%')\n",
    ")\n",
    "\n",
    "max_length_slider = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=50,\n",
    "    max=200,\n",
    "    step=10,\n",
    "    description='Max Length:',\n",
    "    continuous_update=False,\n",
    "    layout=widgets.Layout(width='45%')\n",
    ")\n",
    "\n",
    "generate_btn = widgets.Button(\n",
    "    description='üöÄ Generate',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='200px', height='45px')\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Example prompts\n",
    "examples = [\n",
    "    \"What should policymakers prioritize to address climate change?\",\n",
    "    \"Develop a plan to improve team productivity and collaboration.\",\n",
    "    \"How should we approach solving the housing affordability crisis?\",\n",
    "    \"Create a strategy for improving public health outcomes.\",\n",
    "    \"What investments should we make in education and workforce development?\",\n",
    "]\n",
    "\n",
    "example_btns = []\n",
    "for ex in examples:\n",
    "    btn = widgets.Button(\n",
    "        description=ex[:50] + '...' if len(ex) > 50 else ex,\n",
    "        button_style='info',\n",
    "        layout=widgets.Layout(width='auto', margin='3px')\n",
    "    )\n",
    "    btn.example_text = ex\n",
    "    example_btns.append(btn)\n",
    "\n",
    "# Event handlers\n",
    "def update_steering_label(change):\n",
    "    val = change['new']\n",
    "    if val < -0.6:\n",
    "        label = f\"üî• Strong Immediate ({val:.1f})\"\n",
    "        color = \"#e74c3c\"\n",
    "    elif val < -0.2:\n",
    "        label = f\"üî• Moderate Immediate ({val:.1f})\"\n",
    "        color = \"#e67e22\"\n",
    "    elif val < 0.2:\n",
    "        label = f\"‚öñÔ∏è Neutral ({val:.1f})\"\n",
    "        color = \"#667eea\"\n",
    "    elif val < 0.6:\n",
    "        label = f\"üå± Moderate Long-term ({val:.1f})\"\n",
    "        color = \"#27ae60\"\n",
    "    else:\n",
    "        label = f\"üå± Strong Long-term ({val:.1f})\"\n",
    "        color = \"#16a085\"\n",
    "    \n",
    "    steering_label.value = f'<div style=\"text-align: center; font-size: 18px; font-weight: bold; color: {color}; padding: 10px; background: #f8f9fa; border-radius: 8px;\">{label}</div>'\n",
    "\n",
    "steering_slider.observe(update_steering_label, names='value')\n",
    "\n",
    "def set_example(b):\n",
    "    prompt_input.value = b.example_text\n",
    "\n",
    "for btn in example_btns:\n",
    "    btn.on_click(set_example)\n",
    "\n",
    "def on_generate(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        \n",
    "        display(HTML('''\n",
    "        <div style=\"padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                    border-radius: 12px; color: white; text-align: center; margin: 10px 0;\">\n",
    "            <h3 style=\"margin: 0;\">üîÑ Generating...</h3>\n",
    "        </div>\n",
    "        '''))\n",
    "        \n",
    "        try:\n",
    "            result = steering.generate(\n",
    "                prompt=prompt_input.value,\n",
    "                steering_strength=steering_slider.value,\n",
    "                temperature=temp_slider.value,\n",
    "                max_length=max_length_slider.value\n",
    "            )\n",
    "            \n",
    "            clear_output()\n",
    "            \n",
    "            val = steering_slider.value\n",
    "            if val < -0.6:\n",
    "                header_text = \"üî• Strong Immediate Steering\"\n",
    "                gradient = \"linear-gradient(135deg, #e74c3c 0%, #c0392b 100%)\"\n",
    "            elif val < -0.2:\n",
    "                header_text = \"üî• Moderate Immediate Steering\"\n",
    "                gradient = \"linear-gradient(135deg, #e67e22 0%, #d35400 100%)\"\n",
    "            elif val < 0.2:\n",
    "                header_text = \"‚öñÔ∏è Neutral (No Steering)\"\n",
    "                gradient = \"linear-gradient(135deg, #667eea 0%, #764ba2 100%)\"\n",
    "            elif val < 0.6:\n",
    "                header_text = \"üå± Moderate Long-term Steering\"\n",
    "                gradient = \"linear-gradient(135deg, #27ae60 0%, #229954 100%)\"\n",
    "            else:\n",
    "                header_text = \"üå± Strong Long-term Steering\"\n",
    "                gradient = \"linear-gradient(135deg, #16a085 0%, #138d75 100%)\"\n",
    "            \n",
    "            html = f'''\n",
    "            <div style=\"padding: 20px; background: {gradient}; \n",
    "                        border-radius: 12px; color: white; margin-bottom: 15px;\">\n",
    "                <h3 style=\"margin: 0;\">{header_text} ({val:.1f})</h3>\n",
    "            </div>\n",
    "            <div style=\"padding: 25px; background: #f8f9fa; border-left: 5px solid #667eea; \n",
    "                        border-radius: 8px; line-height: 1.8; font-size: 15px;\">\n",
    "                <pre style=\"white-space: pre-wrap; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; margin: 0;\">{result}</pre>\n",
    "            </div>\n",
    "            '''\n",
    "            display(HTML(html))\n",
    "            \n",
    "        except Exception as e:\n",
    "            clear_output()\n",
    "            display(HTML(f'''\n",
    "            <div style=\"padding: 20px; background: #fee; border-radius: 8px; color: #c00; border: 2px solid #c00;\">\n",
    "                <strong>‚ö†Ô∏è Error:</strong> {str(e)}\n",
    "            </div>\n",
    "            '''))\n",
    "\n",
    "generate_btn.on_click(on_generate)\n",
    "\n",
    "# Display UI\n",
    "display(HTML('''\n",
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 15px; color: white; margin: 20px 0;\">\n",
    "    <h1 style=\"margin: 0 0 10px 0; text-align: center;\">üéÆ Interactive Temporal Steering</h1>\n",
    "    <p style=\"margin: 0; text-align: center; font-size: 16px; opacity: 0.95;\">Control GPT-2's temporal perspective in real-time</p>\n",
    "</div>\n",
    "'''))\n",
    "\n",
    "display(HTML('<h3 style=\"margin-top: 20px;\">üìù Example Prompts</h3>'))\n",
    "display(widgets.HBox(example_btns, layout=widgets.Layout(flex_flow='row wrap')))\n",
    "\n",
    "display(HTML('<h3 style=\"margin-top: 25px;\">‚úèÔ∏è Your Prompt</h3>'))\n",
    "display(prompt_input)\n",
    "\n",
    "display(HTML('<h3 style=\"margin-top: 25px;\">üéöÔ∏è Steering Controls</h3>'))\n",
    "display(steering_label)\n",
    "display(HTML('<div style=\"padding: 0 20px;\"><div style=\"background: linear-gradient(to right, #e74c3c 0%, #95a5a6 50%, #27ae60 100%); height: 8px; border-radius: 4px; margin-bottom: 10px;\"></div></div>'))\n",
    "display(steering_slider)\n",
    "\n",
    "display(HTML('<h3 style=\"margin-top: 25px;\">‚öôÔ∏è Generation Settings</h3>'))\n",
    "display(widgets.HBox([temp_slider, max_length_slider]))\n",
    "\n",
    "display(HTML('<div style=\"text-align: center; margin: 25px 0;\"></div>'))\n",
    "display(widgets.HBox([generate_btn], layout=widgets.Layout(justify_content='center')))\n",
    "\n",
    "display(HTML('<h3 style=\"margin-top: 30px;\">üì§ Generated Output</h3>'))\n",
    "display(output_area)\n",
    "\n",
    "display(HTML('''\n",
    "<div style=\"margin-top: 40px; padding: 20px; background: #f8f9fa; border-radius: 10px; border-left: 4px solid #667eea;\">\n",
    "    <h4 style=\"margin-top: 0;\">üí° Tips:</h4>\n",
    "    <ul style=\"line-height: 1.8;\">\n",
    "        <li><strong>Immediate (-1.0):</strong> Tactical, short-term, concrete actions</li>\n",
    "        <li><strong>Neutral (0.0):</strong> Unsteered GPT-2 baseline</li>\n",
    "        <li><strong>Long-term (+1.0):</strong> Strategic, long-term, systemic thinking</li>\n",
    "        <li><strong>Temperature:</strong> Lower = more focused, Higher = more creative</li>\n",
    "    </ul>\n",
    "</div>\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Side-by-Side Comparison\n",
    "\n",
    "Compare immediate vs. long-term steering directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_steering(prompt, strength=0.8):\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nüî• IMMEDIATE STEERING (-{strength})\")\n",
    "    print(\"-\"*80)\n",
    "    immediate = steering.generate(prompt, steering_strength=-strength, temperature=0.7, max_length=100)\n",
    "    print(immediate)\n",
    "    \n",
    "    print(f\"\\n‚öñÔ∏è  NEUTRAL (0.0)\")\n",
    "    print(\"-\"*80)\n",
    "    neutral = steering.generate(prompt, steering_strength=0.0, temperature=0.7, max_length=100)\n",
    "    print(neutral)\n",
    "    \n",
    "    print(f\"\\nüå± LONG-TERM STEERING (+{strength})\")\n",
    "    print(\"-\"*80)\n",
    "    long_term = steering.generate(prompt, steering_strength=strength, temperature=0.7, max_length=100)\n",
    "    print(long_term)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Try it!\n",
    "compare_steering(\"What should policymakers prioritize to address climate change?\", strength=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Learn More\n",
    "\n",
    "- **GitHub**: [github.com/justinshenk/temporal-steering](https://github.com/justinshenk/temporal-steering)\n",
    "- **Paper**: [Representation Engineering](https://arxiv.org/abs/2310.01405)\n",
    "- **Steering Vectors**: [github.com/steering-vectors/steering-vectors](https://github.com/steering-vectors/steering-vectors)\n",
    "\n",
    "---\n",
    "\n",
    "**Built using Contrastive Activation Addition (CAA)**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Temporal Steering - Interactive Demo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
