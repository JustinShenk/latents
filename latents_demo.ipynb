{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ‚è±Ô∏è Temporal Steering with GPT-2\n",
    "\n",
    "This notebook demonstrates **Contrastive Activation Addition (CAA)** to steer GPT-2's temporal scope from immediate/short-term thinking to long-term/strategic thinking.\n",
    "\n",
    "## What is Temporal Steering?\n",
    "\n",
    "We extract \"steering vectors\" by comparing activations from:\n",
    "- **Immediate prompts**: \"Develop a 1 week plan to...\"\n",
    "- **Long-term prompts**: \"Develop a 20 year plan to...\"\n",
    "\n",
    "These vectors capture the difference in how the model represents immediate vs. long-term thinking, and we can add them during generation to shift the model's temporal perspective.\n",
    "\n",
    "## Approach\n",
    "\n",
    "1. Extract activations from prompt pairs with different temporal horizons\n",
    "2. Compute contrastive vectors: `steering_vector = long_term_activations - immediate_activations`\n",
    "3. Apply steering during generation by adding vectors to hidden states\n",
    "4. Observe how responses shift between tactical and strategic thinking\n",
    "\n",
    "---\n",
    "\n",
    "**Based on:** [Contrastive Activation Addition](https://github.com/steering-vectors/steering-vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers torch numpy matplotlib ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data"
   },
   "source": [
    "## 2. Prepare Prompt Pairs\n",
    "\n",
    "We create pairs of prompts that differ only in their temporal horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prompt_pairs"
   },
   "outputs": [],
   "source": [
    "# Sample prompt pairs for steering vector extraction\n",
    "PROMPT_PAIRS = [\n",
    "    {\n",
    "        \"task\": \"establishing a new data center with procurement of servers, storage, and network infrastructure\",\n",
    "        \"immediate\": \"Develop a 1 week plan to establishing a new data center with procurement of servers, storage, and network infrastructure.\",\n",
    "        \"long_term\": \"Develop a 20 years plan to establishing a new data center with procurement of servers, storage, and network infrastructure.\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"develop a comprehensive marketing strategy including market research and target audiences\",\n",
    "        \"immediate\": \"Develop a 1 month plan to develop a comprehensive marketing strategy including market research and target audiences.\",\n",
    "        \"long_term\": \"Develop a 10 years plan to develop a comprehensive marketing strategy including market research and target audiences.\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"improve team productivity and collaboration across the organization\",\n",
    "        \"immediate\": \"Develop a 1 week plan to improve team productivity and collaboration across the organization.\",\n",
    "        \"long_term\": \"Develop a 10 years plan to improve team productivity and collaboration across the organization.\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"address climate change and reduce carbon emissions\",\n",
    "        \"immediate\": \"Develop a 1 month plan to address climate change and reduce carbon emissions.\",\n",
    "        \"long_term\": \"Develop a 50 years plan to address climate change and reduce carbon emissions.\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"expand operations to new markets and locations\",\n",
    "        \"immediate\": \"Develop a 1 month plan to expand operations to new markets and locations.\",\n",
    "        \"long_term\": \"Develop a 20 years plan to expand operations to new markets and locations.\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"improve public health outcomes and healthcare access\",\n",
    "        \"immediate\": \"Develop a 1 week plan to improve public health outcomes and healthcare access.\",\n",
    "        \"long_term\": \"Develop a 30 years plan to improve public health outcomes and healthcare access.\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"modernize education system and workforce development\",\n",
    "        \"immediate\": \"Develop a 1 month plan to modernize education system and workforce development.\",\n",
    "        \"long_term\": \"Develop a 25 years plan to modernize education system and workforce development.\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"implement digital transformation across business operations\",\n",
    "        \"immediate\": \"Develop a 1 week plan to implement digital transformation across business operations.\",\n",
    "        \"long_term\": \"Develop a 15 years plan to implement digital transformation across business operations.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"Prepared {len(PROMPT_PAIRS)} prompt pairs\")\n",
    "print(\"\\nExample pair:\")\n",
    "print(f\"Immediate: {PROMPT_PAIRS[0]['immediate']}\")\n",
    "print(f\"Long-term: {PROMPT_PAIRS[0]['long_term']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_load"
   },
   "source": [
    "## 3. Load Model\n",
    "\n",
    "We'll use GPT-2 (124M parameters) which runs efficiently on CPU/GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "# Load GPT-2\n",
    "print(\"Loading GPT-2...\")\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.eval()\n",
    "\n",
    "# Move to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"‚úì Model loaded on {device}\")\n",
    "print(f\"  Model: GPT-2 (124M parameters)\")\n",
    "print(f\"  Layers: {len(model.transformer.h)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "extract"
   },
   "source": [
    "## 4. Extract Steering Vectors\n",
    "\n",
    "Extract activations from each layer and compute contrastive vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extraction_functions"
   },
   "outputs": [],
   "source": [
    "def extract_activations(model, tokenizer, prompt: str, device: str) -> Dict[int, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Extract activations from all layers for a given prompt.\n",
    "    \n",
    "    Returns: dict mapping layer_idx -> activations (seq_len, hidden_dim)\n",
    "    \"\"\"\n",
    "    activations = {}\n",
    "    \n",
    "    def hook_fn(layer_num):\n",
    "        def hook(module, input, output):\n",
    "            # output[0] is the hidden states\n",
    "            activations[layer_num] = output[0].detach()\n",
    "        return hook\n",
    "    \n",
    "    # Register hooks for all layers\n",
    "    hooks = []\n",
    "    for i, layer in enumerate(model.transformer.h):\n",
    "        hook = layer.register_forward_hook(hook_fn(i))\n",
    "        hooks.append(hook)\n",
    "    \n",
    "    # Forward pass\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        model(**inputs)\n",
    "    \n",
    "    # Remove hooks\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "    \n",
    "    return activations\n",
    "\n",
    "\n",
    "def compute_steering_vectors(model, tokenizer, prompt_pairs: List[Dict], device: str) -> Dict[int, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute steering vectors from prompt pairs.\n",
    "    \n",
    "    Returns: dict mapping layer_idx -> steering_vector (hidden_dim,)\n",
    "    \"\"\"\n",
    "    n_layers = len(model.transformer.h)\n",
    "    layer_contrasts = {layer: [] for layer in range(n_layers)}\n",
    "    \n",
    "    print(f\"Extracting activations from {len(prompt_pairs)} prompt pairs...\")\n",
    "    \n",
    "    for pair in tqdm(prompt_pairs):\n",
    "        # Extract activations\n",
    "        immediate_acts = extract_activations(model, tokenizer, pair['immediate'], device)\n",
    "        long_term_acts = extract_activations(model, tokenizer, pair['long_term'], device)\n",
    "        \n",
    "        # Compute contrastive vectors at each layer\n",
    "        for layer in range(n_layers):\n",
    "            # Take final token position\n",
    "            imm_vec = immediate_acts[layer][0, -1, :].cpu().numpy()\n",
    "            long_vec = long_term_acts[layer][0, -1, :].cpu().numpy()\n",
    "            \n",
    "            # Contrastive vector: long_term - immediate\n",
    "            contrast = long_vec - imm_vec\n",
    "            layer_contrasts[layer].append(contrast)\n",
    "    \n",
    "    # Average across all pairs\n",
    "    steering_vectors = {}\n",
    "    for layer in range(n_layers):\n",
    "        contrasts = np.stack(layer_contrasts[layer])\n",
    "        steering_vectors[layer] = contrasts.mean(axis=0)\n",
    "    \n",
    "    return steering_vectors\n",
    "\n",
    "print(\"‚úì Extraction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_extraction"
   },
   "outputs": [],
   "source": [
    "# Extract steering vectors\n",
    "steering_vectors = compute_steering_vectors(model, tokenizer, PROMPT_PAIRS, device)\n",
    "\n",
    "print(f\"\\n‚úì Extracted steering vectors for {len(steering_vectors)} layers\")\n",
    "print(f\"  Vector dimension: {len(steering_vectors[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analyze"
   },
   "source": [
    "## 5. Analyze Steering Vectors\n",
    "\n",
    "Visualize the strength of steering vectors across layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize"
   },
   "outputs": [],
   "source": [
    "# Compute norms for each layer\n",
    "layer_norms = {layer: np.linalg.norm(vec) for layer, vec in steering_vectors.items()}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Bar plot of norms\n",
    "plt.subplot(1, 2, 1)\n",
    "layers = list(layer_norms.keys())\n",
    "norms = list(layer_norms.values())\n",
    "plt.bar(layers, norms, color='steelblue', alpha=0.7)\n",
    "plt.xlabel('Layer', fontsize=12)\n",
    "plt.ylabel('Steering Vector Norm', fontsize=12)\n",
    "plt.title('Steering Vector Strength by Layer', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Cumulative view\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(layers, norms, marker='o', linewidth=2, markersize=8, color='coral')\n",
    "plt.xlabel('Layer', fontsize=12)\n",
    "plt.ylabel('Steering Vector Norm', fontsize=12)\n",
    "plt.title('Steering Effect Across Layers', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print top layers\n",
    "sorted_layers = sorted(layer_norms.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 5 layers with strongest steering effect:\")\n",
    "for layer, norm in sorted_layers[:5]:\n",
    "    print(f\"  Layer {layer:2d}: {norm:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "steer"
   },
   "source": [
    "## 6. Apply Temporal Steering\n",
    "\n",
    "Now we can steer the model during generation by adding our steering vectors to the activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "steering_class"
   },
   "outputs": [],
   "source": [
    "class TemporalSteering:\n",
    "    \"\"\"Apply temporal steering vectors during generation.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, steering_vectors, target_layers=None):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.steering_vectors = steering_vectors\n",
    "        \n",
    "        # Default to middle-to-late layers\n",
    "        if target_layers is None:\n",
    "            n_layers = len(model.transformer.h)\n",
    "            start = max(0, n_layers - 8)\n",
    "            self.target_layers = list(range(start, n_layers))\n",
    "        else:\n",
    "            self.target_layers = target_layers\n",
    "    \n",
    "    def generate(self, prompt: str, steering_strength: float = 0.0, \n",
    "                 max_length: int = 100, temperature: float = 0.7, **kwargs):\n",
    "        \"\"\"\n",
    "        Generate text with temporal steering.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Input text\n",
    "            steering_strength: -1.0 (immediate) to +1.0 (long-term)\n",
    "            max_length: Maximum tokens\n",
    "            temperature: Sampling temperature\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors='pt').to(self.model.device)\n",
    "        input_ids = inputs['input_ids']\n",
    "        \n",
    "        # Register steering hooks\n",
    "        hooks = []\n",
    "        \n",
    "        def make_hook(layer_idx, strength):\n",
    "            def hook(module, input, output):\n",
    "                hidden_states = output[0]\n",
    "                \n",
    "                if layer_idx in self.steering_vectors:\n",
    "                    steering_vec = torch.tensor(\n",
    "                        self.steering_vectors[layer_idx],\n",
    "                        dtype=hidden_states.dtype,\n",
    "                        device=hidden_states.device\n",
    "                    )\n",
    "                    hidden_states = hidden_states + strength * steering_vec\n",
    "                \n",
    "                return (hidden_states,) + output[1:]\n",
    "            return hook\n",
    "        \n",
    "        # Register hooks\n",
    "        for layer_idx in self.target_layers:\n",
    "            hook = self.model.transformer.h[layer_idx].register_forward_hook(\n",
    "                make_hook(layer_idx, steering_strength)\n",
    "            )\n",
    "            hooks.append(hook)\n",
    "        \n",
    "        # Generate\n",
    "        with torch.no_grad():\n",
    "            output_ids = self.model.generate(\n",
    "                input_ids,\n",
    "                max_length=max_length,\n",
    "                temperature=temperature,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                **kwargs\n",
    "            )\n",
    "        \n",
    "        # Remove hooks\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        # Decode\n",
    "        generated = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        return generated\n",
    "\n",
    "# Initialize steering system\n",
    "steering_system = TemporalSteering(model, tokenizer, steering_vectors)\n",
    "print(f\"‚úì Steering system ready (layers {steering_system.target_layers[0]}-{steering_system.target_layers[-1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "demo"
   },
   "source": [
    "## 7. Interactive Demo\n",
    "\n",
    "Try steering GPT-2's temporal scope with the interactive controls below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interactive_demo"
   },
   "outputs": [],
   "source": [
    "# Create interactive widgets\n",
    "prompt_input = widgets.Textarea(\n",
    "    value='What should policymakers prioritize to address climate change?',\n",
    "    placeholder='Enter your prompt...',\n",
    "    description='Prompt:',\n",
    "    layout=widgets.Layout(width='100%', height='80px')\n",
    ")\n",
    "\n",
    "steering_slider = widgets.FloatSlider(\n",
    "    value=0.0,\n",
    "    min=-1.0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description='Temporal Steering:',\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "temp_slider = widgets.FloatSlider(\n",
    "    value=0.7,\n",
    "    min=0.1,\n",
    "    max=1.5,\n",
    "    step=0.1,\n",
    "    description='Temperature:',\n",
    "    continuous_update=False,\n",
    "    readout_format='.1f',\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "max_length_slider = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=50,\n",
    "    max=200,\n",
    "    step=10,\n",
    "    description='Max Length:',\n",
    "    continuous_update=False,\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "generate_button = widgets.Button(\n",
    "    description='Generate',\n",
    "    button_style='primary',\n",
    "    icon='play',\n",
    "    layout=widgets.Layout(width='150px', height='40px')\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Example prompts\n",
    "example_buttons = []\n",
    "examples = [\n",
    "    \"What should policymakers prioritize to address climate change?\",\n",
    "    \"Develop a plan to improve team productivity and collaboration.\",\n",
    "    \"How should we approach solving the housing affordability crisis?\",\n",
    "    \"Create a strategy for digital transformation in our organization.\",\n",
    "    \"What investments should we make in education and workforce development?\",\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    btn = widgets.Button(\n",
    "        description=example[:40] + '...' if len(example) > 40 else example,\n",
    "        layout=widgets.Layout(width='auto', margin='2px'),\n",
    "        button_style='info'\n",
    "    )\n",
    "    btn.example_text = example\n",
    "    example_buttons.append(btn)\n",
    "\n",
    "# Event handlers\n",
    "def set_example(b):\n",
    "    prompt_input.value = b.example_text\n",
    "\n",
    "for btn in example_buttons:\n",
    "    btn.on_click(set_example)\n",
    "\n",
    "def on_generate(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        \n",
    "        # Show loading\n",
    "        display(HTML('<div style=\"padding: 20px; background: #f0f0f0; border-radius: 8px;\"><h3>üîÑ Generating...</h3></div>'))\n",
    "        \n",
    "        try:\n",
    "            # Generate\n",
    "            result = steering_system.generate(\n",
    "                prompt=prompt_input.value,\n",
    "                steering_strength=steering_slider.value,\n",
    "                temperature=temp_slider.value,\n",
    "                max_length=max_length_slider.value\n",
    "            )\n",
    "            \n",
    "            clear_output()\n",
    "            \n",
    "            # Display result\n",
    "            steering_label = \"Neutral\"\n",
    "            if steering_slider.value < -0.6:\n",
    "                steering_label = \"Strong Immediate üî•\"\n",
    "            elif steering_slider.value < -0.2:\n",
    "                steering_label = \"Moderate Immediate\"\n",
    "            elif steering_slider.value < 0.2:\n",
    "                steering_label = \"Neutral ‚öñÔ∏è\"\n",
    "            elif steering_slider.value < 0.6:\n",
    "                steering_label = \"Moderate Long-term\"\n",
    "            else:\n",
    "                steering_label = \"Strong Long-term üå±\"\n",
    "            \n",
    "            html = f\"\"\"\n",
    "            <div style=\"padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 12px; color: white; margin-bottom: 15px;\">\n",
    "                <h3 style=\"margin: 0;\">Temporal Steering: {steering_label} ({steering_slider.value:.1f})</h3>\n",
    "            </div>\n",
    "            <div style=\"padding: 20px; background: #f8f9fa; border-left: 4px solid #667eea; border-radius: 8px; line-height: 1.6;\">\n",
    "                <pre style=\"white-space: pre-wrap; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; margin: 0;\">{result}</pre>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            display(HTML(html))\n",
    "            \n",
    "        except Exception as e:\n",
    "            clear_output()\n",
    "            display(HTML(f'<div style=\"padding: 20px; background: #fee; border-radius: 8px; color: #c00;\"><strong>Error:</strong> {str(e)}</div>'))\n",
    "\n",
    "generate_button.on_click(on_generate)\n",
    "\n",
    "# Layout\n",
    "display(HTML('<h2>üéÆ Interactive Temporal Steering Demo</h2>'))\n",
    "display(HTML('<p style=\"color: #666;\">Adjust the slider to shift between immediate/tactical thinking (-1.0) and long-term/strategic thinking (+1.0)</p>'))\n",
    "display(HTML('<hr style=\"margin: 20px 0;\">'))\n",
    "\n",
    "display(HTML('<h4>Example Prompts:</h4>'))\n",
    "display(widgets.HBox(example_buttons, layout=widgets.Layout(flex_flow='row wrap')))\n",
    "display(HTML('<br>'))\n",
    "\n",
    "display(prompt_input)\n",
    "display(HTML('<br>'))\n",
    "display(steering_slider)\n",
    "display(widgets.HBox([temp_slider, max_length_slider]))\n",
    "display(HTML('<br>'))\n",
    "display(generate_button)\n",
    "display(HTML('<br>'))\n",
    "display(output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison"
   },
   "source": [
    "## 8. Side-by-Side Comparison\n",
    "\n",
    "Compare immediate vs. long-term steering directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison_demo"
   },
   "outputs": [],
   "source": [
    "def compare_steering(prompt: str, strength: float = 0.8):\n",
    "    \"\"\"\n",
    "    Generate responses with immediate (-strength) and long-term (+strength) steering.\n",
    "    \"\"\"\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Immediate\n",
    "    print(f\"\\nüî• IMMEDIATE STEERING (-{strength})\")\n",
    "    print(\"-\"*80)\n",
    "    immediate = steering_system.generate(\n",
    "        prompt=prompt,\n",
    "        steering_strength=-strength,\n",
    "        temperature=0.7,\n",
    "        max_length=100\n",
    "    )\n",
    "    print(immediate)\n",
    "    \n",
    "    # Long-term\n",
    "    print(f\"\\nüå± LONG-TERM STEERING (+{strength})\")\n",
    "    print(\"-\"*80)\n",
    "    long_term = steering_system.generate(\n",
    "        prompt=prompt,\n",
    "        steering_strength=strength,\n",
    "        temperature=0.7,\n",
    "        max_length=100\n",
    "    )\n",
    "    print(long_term)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Try it!\n",
    "compare_steering(\"What should policymakers prioritize to address climate change?\", strength=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "experiments"
   },
   "source": [
    "## 9. Experiment: Your Own Prompts\n",
    "\n",
    "Try your own prompts and observe how steering affects the responses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom_experiment"
   },
   "outputs": [],
   "source": [
    "# Try your own!\n",
    "my_prompt = \"How should we improve workplace culture and employee wellbeing?\"\n",
    "\n",
    "compare_steering(my_prompt, strength=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## üéØ Key Takeaways\n",
    "\n",
    "1. **Steering vectors** encode the difference between immediate and long-term thinking in model activations\n",
    "2. **Later layers** show stronger steering effects (layers 9-11 for GPT-2)\n",
    "3. **Positive steering** (+1.0) pushes toward strategic/long-term thinking\n",
    "4. **Negative steering** (-1.0) pushes toward tactical/immediate thinking\n",
    "5. **Temperature** controls randomness - lower = more focused\n",
    "\n",
    "## üî¨ Further Exploration\n",
    "\n",
    "- Try different model sizes (gpt2-medium, gpt2-large)\n",
    "- Extract steering vectors from your own prompt pairs\n",
    "- Experiment with layer selection (early vs. late layers)\n",
    "- Combine temporal steering with other steering dimensions\n",
    "- Test on decision-making scenarios with temporal trade-offs\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [Steering Vectors Library](https://github.com/steering-vectors/steering-vectors)\n",
    "- [Representation Engineering Paper](https://arxiv.org/abs/2310.01405)\n",
    "- [GPT-2 Paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "\n",
    "---\n",
    "\n",
    "**Built with ‚ù§Ô∏è using Contrastive Activation Addition**\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Temporal Steering with GPT-2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
